{"model_name": "biobert", "n_epochs": 10, "train_bs": 128, "test_bs": 64, "learning_rate": [[1.8e-05], [1.6000000000000003e-05], [1.4e-05], [1.2e-05], [1e-05], [8.000000000000001e-06], [6e-06], [4.000000000000001e-06], [2.0000000000000003e-06], [0.0]], "dgpus": true, "train_loss": [0.18469336056716684, 0.10353904158205127, 0.07569718054003514, 0.05525351641121928, 0.03984775913188294, 0.028314536398105675, 0.01882318917637857, 0.013470218057941215, 0.009630944734404156, 0.00732994385866134], "train_acc": [0.9264880200540215, 0.9631565651658538, 0.9741746176716348, 0.9815977147742951, 0.9869221352091876, 0.9906725481432541, 0.9941897747809021, 0.9957249178989914, 0.9972017644429763, 0.9977264336099182], "test_acc": [0.9552273610571318, 0.9562378546443839, 0.9547609794014769, 0.9562378546443839, 0.9605907500971629, 0.9591138748542557, 0.9579479207151186, 0.9548387096774194, 0.9578701904391761, 0.9572483482316362], "test_classification": ["              precision    recall  f1-score   support\n\n           0       0.94      0.96      0.95      5663\n           1       0.96      0.96      0.96      7202\n\n    accuracy                           0.96     12865\n   macro avg       0.95      0.96      0.95     12865\nweighted avg       0.96      0.96      0.96     12865\n", "              precision    recall  f1-score   support\n\n           0       0.94      0.96      0.95      5663\n           1       0.97      0.95      0.96      7202\n\n    accuracy                           0.96     12865\n   macro avg       0.95      0.96      0.96     12865\nweighted avg       0.96      0.96      0.96     12865\n", "              precision    recall  f1-score   support\n\n           0       0.93      0.97      0.95      5663\n           1       0.98      0.94      0.96      7202\n\n    accuracy                           0.95     12865\n   macro avg       0.95      0.96      0.95     12865\nweighted avg       0.96      0.95      0.95     12865\n", "              precision    recall  f1-score   support\n\n           0       0.94      0.97      0.95      5663\n           1       0.97      0.95      0.96      7202\n\n    accuracy                           0.96     12865\n   macro avg       0.95      0.96      0.96     12865\nweighted avg       0.96      0.96      0.96     12865\n", "              precision    recall  f1-score   support\n\n           0       0.94      0.97      0.96      5663\n           1       0.97      0.96      0.96      7202\n\n    accuracy                           0.96     12865\n   macro avg       0.96      0.96      0.96     12865\nweighted avg       0.96      0.96      0.96     12865\n", "              precision    recall  f1-score   support\n\n           0       0.94      0.97      0.95      5663\n           1       0.97      0.95      0.96      7202\n\n    accuracy                           0.96     12865\n   macro avg       0.96      0.96      0.96     12865\nweighted avg       0.96      0.96      0.96     12865\n", "              precision    recall  f1-score   support\n\n           0       0.94      0.96      0.95      5663\n           1       0.97      0.95      0.96      7202\n\n    accuracy                           0.96     12865\n   macro avg       0.96      0.96      0.96     12865\nweighted avg       0.96      0.96      0.96     12865\n", "              precision    recall  f1-score   support\n\n           0       0.93      0.97      0.95      5663\n           1       0.97      0.94      0.96      7202\n\n    accuracy                           0.95     12865\n   macro avg       0.95      0.96      0.95     12865\nweighted avg       0.96      0.95      0.95     12865\n", "              precision    recall  f1-score   support\n\n           0       0.94      0.96      0.95      5663\n           1       0.97      0.95      0.96      7202\n\n    accuracy                           0.96     12865\n   macro avg       0.96      0.96      0.96     12865\nweighted avg       0.96      0.96      0.96     12865\n", "              precision    recall  f1-score   support\n\n           0       0.94      0.96      0.95      5663\n           1       0.97      0.95      0.96      7202\n\n    accuracy                           0.96     12865\n   macro avg       0.96      0.96      0.96     12865\nweighted avg       0.96      0.96      0.96     12865\n"]}