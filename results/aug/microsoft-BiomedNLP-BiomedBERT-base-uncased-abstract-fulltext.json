{"model_name": "pubmed-fulltext", "n_epochs": 10, "train_bs": 128, "test_bs": 64, "learning_rate": [[1.8e-05], [1.6000000000000003e-05], [1.4e-05], [1.2e-05], [1e-05], [8.000000000000001e-06], [6e-06], [4.000000000000001e-06], [2.0000000000000003e-06], [0.0]], "dgpus": true, "train_loss": [0.1705817193273575, 0.09519608528815468, 0.0736300478742525, 0.05626816706496196, 0.040543627587526054, 0.031033326912424053, 0.02383660382673372, 0.016576549890679342, 0.011579296830369947, 0.009370206016344848], "train_acc": [0.9350770486387749, 0.9669264102912886, 0.9739802957579526, 0.9816948757311362, 0.9857756359184625, 0.9896815063834749, 0.9922465556440799, 0.9946367151823711, 0.9963467480227746, 0.9969297137638211], "test_acc": [0.9509521958802953, 0.9612125923047027, 0.9651768363777692, 0.963855421686747, 0.9623008161678974, 0.9593470656820832, 0.9571706179556937, 0.9541391371939371, 0.9582588418188884, 0.9559269335406141], "test_classification": ["              precision    recall  f1-score   support\n\n           0       0.92      0.97      0.95      5663\n           1       0.97      0.94      0.96      7202\n\n    accuracy                           0.95     12865\n   macro avg       0.95      0.95      0.95     12865\nweighted avg       0.95      0.95      0.95     12865\n", "              precision    recall  f1-score   support\n\n           0       0.95      0.97      0.96      5663\n           1       0.97      0.96      0.97      7202\n\n    accuracy                           0.96     12865\n   macro avg       0.96      0.96      0.96     12865\nweighted avg       0.96      0.96      0.96     12865\n", "              precision    recall  f1-score   support\n\n           0       0.96      0.96      0.96      5663\n           1       0.97      0.97      0.97      7202\n\n    accuracy                           0.97     12865\n   macro avg       0.96      0.96      0.96     12865\nweighted avg       0.97      0.97      0.97     12865\n", "              precision    recall  f1-score   support\n\n           0       0.95      0.97      0.96      5663\n           1       0.97      0.96      0.97      7202\n\n    accuracy                           0.96     12865\n   macro avg       0.96      0.96      0.96     12865\nweighted avg       0.96      0.96      0.96     12865\n", "              precision    recall  f1-score   support\n\n           0       0.95      0.97      0.96      5663\n           1       0.97      0.96      0.97      7202\n\n    accuracy                           0.96     12865\n   macro avg       0.96      0.96      0.96     12865\nweighted avg       0.96      0.96      0.96     12865\n", "              precision    recall  f1-score   support\n\n           0       0.94      0.97      0.95      5663\n           1       0.97      0.95      0.96      7202\n\n    accuracy                           0.96     12865\n   macro avg       0.96      0.96      0.96     12865\nweighted avg       0.96      0.96      0.96     12865\n", "              precision    recall  f1-score   support\n\n           0       0.93      0.98      0.95      5663\n           1       0.98      0.94      0.96      7202\n\n    accuracy                           0.96     12865\n   macro avg       0.96      0.96      0.96     12865\nweighted avg       0.96      0.96      0.96     12865\n", "              precision    recall  f1-score   support\n\n           0       0.93      0.97      0.95      5663\n           1       0.98      0.94      0.96      7202\n\n    accuracy                           0.95     12865\n   macro avg       0.95      0.96      0.95     12865\nweighted avg       0.96      0.95      0.95     12865\n", "              precision    recall  f1-score   support\n\n           0       0.94      0.97      0.95      5663\n           1       0.98      0.95      0.96      7202\n\n    accuracy                           0.96     12865\n   macro avg       0.96      0.96      0.96     12865\nweighted avg       0.96      0.96      0.96     12865\n", "              precision    recall  f1-score   support\n\n           0       0.93      0.97      0.95      5663\n           1       0.98      0.94      0.96      7202\n\n    accuracy                           0.96     12865\n   macro avg       0.95      0.96      0.96     12865\nweighted avg       0.96      0.96      0.96     12865\n"]}